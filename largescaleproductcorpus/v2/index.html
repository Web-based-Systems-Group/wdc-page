<!DOCTYPE html>
<html>

<head>
	<title>WDC Product Data Corpus and Gold Standard for Large-Scale Product Matching v2.0</title>
	<link rel='stylesheet' href='http://webdatacommons.org/style.css' type='text/css' media='screen' />
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<style>
		.tar {
			text-align: right;
		}

		.rtable {
			float: right;
			padding-left: 10px;
		}

		.smalltable,
		.smalltable TD,
		.smalltable TH {
			font-size: 9pt;
		}

		.tab {
			overflow: hidden;
			border: 1px solid #ccc;
			background-color: #eaf3fa;
			clear: both;
			padding-left: 25px;
			width: 650px;
		}

		.tab button {
			background-color: inherit;
			float: left;
			border: none;
			outline: none;
			cursor: pointer;
			padding: 15px 60px;
			transition: 0.3s;
		}

		.tab button:hover {
			background-color: #ddd;
		}

		.tab button.active {
			background-color: #ccc;
		}

		.tabcontent {
			display: none;
			padding: 6px 12px;
			border-top: none;
			animation: fadeEffect 1s;
			width: 500px
		}

		.table-wrapper {
			position: relative;
		}

		.table-scroll {
			height: 240px;
			overflow: auto;
			margin-top: -10px;
		}

		.show {
			display: block;
		}

		.no-show {
			display: none;
		}

		caption {
			caption-side: top;
			font-style: italic;
		}

		td[scope="mergedcol"] {
			text-align: center;
		}

		tr.bordered {
			border-bottom: 1px solid #000;
		}

		hr {
			width: 50%;
			margin: 20px 0;
			/* This leaves 10px margin on left and right. If only right margin is needed try margin-right: 10px; */
		}

		@keyframes fadeEffect {
			from {
				opacity: 0;
			}

			to {
				opacity: 1;
			}
		}
	</style>
	<script type="text/javascript" src="https://www.google.com/jsapi"></script>
	<script type="text/javascript">
		google.load('visualization', '1', {
			packages: ['bar', 'line', 'corechart']
		});
		google.setOnLoadCallback(drawOffersPerClassChart);
		google.setOnLoadCallback(drawOffersPerClassChartEnglish);
		google.setOnLoadCallback(drawOffersPerTLDChart);
		google.setOnLoadCallback(drawCategDistributionCorpusOffers);
		google.setOnLoadCallback(drawTopProdPropsNov);
		google.setOnLoadCallback(drawIDPropsNov);
		google.setOnLoadCallback(drawStatsGS);
		google.setOnLoadCallback(drawKVpairPerSpecTable);


		function drawTopProdPropsNov() {

			var data = google.visualization.arrayToDataTable([
				["Property", "# PLDs", {
					role: 'annotation'
				}],
				["Product/name", 535625, "92%"],
				["Offer/price", 462444, "80%"],
				["Product/offers", 462233, "79%"],
				["Offer/priceCurrency", 430556, "74%"],
				["Product/image", 419391, "72%"],
				["Product/description", 377639, "65%"],
				["Offer/availability", 337876, "58%"],
				["Product/url", 263720, "45%"],
				["AggregateRating/ratingValue", 184004, "32%"],
				["Product/sku", 126696, "22%"],
				["AggregateRating/reviewCount", 112408, "19%"],
				["Product/aggregateRating", 101434, "17%"],
				["Product/brand", 73934, "13%"],
				["Product/productID", 35211, "6%"],
				["Product/manufacturer", 21967, "4%"]
			]);


			var view = new google.visualization.DataView(data);
			view.setColumns([0, 1,
				{
					calc: "stringify",
					sourceColumn: 1,
					type: "string",
					role: "annotation"
				}
			]);

			var options = {
				title: "Figure 1: Top product-related properties - WDC Product Corpus November 2017",
				width: 600,
				height: 500,
				bar: {
					groupWidth: "75%"
				},
				legend: {
					position: "none"
				},
				hAxis: {
					title: '# PLDs',
					minValue: 0
				},
				vAxis: {
					title: 'schema.org Property',
					textStyle: {
						fontSize: 10
					}
				}
			};

			var chart = new google.visualization.BarChart(document.getElementById("topPropsNov"));
			chart.draw(data, options);
		}

		function drawIDPropsNov() {

			var data = google.visualization.arrayToDataTable([
				["Property", "# Entities", {
					role: 'annotation'
				}],
				["Product/productID", 52173553, "6.44%"],
				["Product/sku", 40281145, "4.97%"],
				["Offer/sku", 18982354, "2.34%"],
				["Product/mpn", 13106410, "1.62%"],
				["Product/gtin13", 4540417, "0.56%"],
				["Offer/gtin13", 669844, "0.08%"],
				["Product/gtin8", 538526, "0.07%"],
				["Product/gtin12", 270870, "0.06%"],
				["Product/gtin14", 453722, "0.06%"],
				["Product/identifier", 411557, "0.05%"],
				["Offer/gtin14", 270870, "0.03%"]

			]);


			var view = new google.visualization.DataView(data);
			view.setColumns([0, 1,
				{
					calc: "stringify",
					sourceColumn: 1,
					type: "string",
					role: "annotation"
				}
			]);

			var options = {
				title: "Figure 2: Product id-related properties per # (schema:Offer & schema:Product) Entities- WDC Product Corpus November 2017",
				width: 600,
				height: 500,
				bar: {
					groupWidth: "75%"
				},
				legend: {
					position: "none"
				},
				hAxis: {
					title: '# Entities',
					minValue: 0
				},
				vAxis: {
					title: 'schema.org Property',
					textStyle: {
						fontSize: 10
					}
				}
			};

			var chart = new google.visualization.BarChart(document.getElementById("idPropsNov"));
			chart.draw(data, options);
		}


		function drawOffersPerClassChart() {

			var data = google.visualization.arrayToDataTable([
				["Offer Entities Count", "Frequency(#ID-clusters)", {
					role: 'annotation'
				}],
				["[>80]", 4978, 137488518],
				["[71-80]", 1058, 2960532],
				["[61-70]", 1378, 2891198],
				["[51-60]", 2663, 3978483],
				["[41-50]", 6318, 6281387],
				["[31-40]", 10863, 6666546],
				["[21-30]", 17710, 5374523],
				["[11-20]", 63981, 6752150],
				["[5-10]", 304379, 5677852],
				["[3-4]", 760360, 3026997],
				["[2]", 1915909, 1915909]

			]);

			var view = new google.visualization.DataView(data);


			var options = {
				title: "Figure 1: Distribution of offers (bar label: #positive pairs) per ID-cluster - Full Product Corpus",
				width: 400,
				height: 400,
				bar: {
					groupWidth: "95%"
				},
				legend: {
					position: "none"
				},
				hAxis: {
					title: 'Frequency(#ID-clusters)',
					minValue: 0
				},
				vAxis: {
					title: '# Offers'
				}
			};

			var chart = new google.visualization.BarChart(document.getElementById("offersPerClass"));
			chart.draw(view, options);
		}

		function drawOffersPerClassChartEnglish() {

			var data = google.visualization.arrayToDataTable([
				["Offer Count", "Frequency(#ID-clusters)", {
					role: 'annotation'
				}],
				["[>80]", 3999, 113935797],
				["[71-80]", 682, 1899880],
				["[61-70]", 832, 1750014],
				["[51-60]", 1300, 1972822],
				["[41-50]", 2504, 2502691],
				["[31-40]", 4461, 2646306],
				["[21-30]", 10567, 3185935],
				["[11-20]", 37562, 3751124],
				["[5-10]", 163356, 3064532],
				["[3-4]", 400522, 1552680],
				["[2]", 1012220, 1012220]

			]);

			var view = new google.visualization.DataView(data);


			var options = {
				title: "Figure 2: Distribution of offers (bar label: #positive pairs) per ID-cluster - English Subset",
				width: 400,
				height: 400,
				bar: {
					groupWidth: "95%"
				},
				legend: {
					position: "none"
				},
				hAxis: {
					title: 'Frequency(#ID-clusters)',
					minValue: 0
				},
				vAxis: {
					title: '# Offers'
				}
			};

			var chart = new google.visualization.BarChart(document.getElementById("offersPerClass_english"));
			chart.draw(view, options);
		}

		function drawOffersPerTLDChart() {

			var data = google.visualization.arrayToDataTable([
				["TLD", "Offer Entities"],
				[" com", 14931548],
				[" de", 2840181],
				[" co.uk", 976658],
				[" ru", 829898],
				[" fr", 476734],
				[" cz", 469539],
				[" net", 469203],
				[" com.au", 437396],
				[" pl", 420077],
				[" nl", 381765],
				[" ca", 342868],
				[" it", 335136],
				[" com.br", 322258],
				[" ch", 302106],
				[" es", 226101],
				["others", 3127330]

			]);


			var options = {
				title: "Figure 3: Distribution of offers per top-level domain (TLD)",
				width: 400,
				height: 400,
				legend: {
					position: "none"
				},
				is3D: true

			};

			var chart = new google.visualization.PieChart(document.getElementById("offersPerTLD"));
			chart.draw(data, options);
		}


		function drawCategDistributionCorpusOffers() {

			var data = google.visualization.arrayToDataTable([
				["Category", "Offers in Corpus", {
					role: 'annotation'
				}],
				["[Office_Products]", 2160426, "13.13%"],
				["[Tools_and_Home_Improvement]", 1547329, "9.41%"],
				["[Home_and_Garden]", 1461979, "8.89%"],
				["[Automotive]", 1376228, "8.37%"],
				["[Clothing]", 1096607, "6.67%"],
				["[Sports_and_Outdoors]", 896801, "5.45%"],
				["[Other_Electronics]", 867129, "5.27%"],
				["[Jewelry]", 813983, "4.95%"],
				["[Books]", 693707, "4.22%"],
				["[Shoes]", 683036, "4.15%"],
				["[Computers_and_Accessories]", 664978, "4.04%"],
				["[Health_and_Beauty]", 646004, "3.93%"],
				["[Toys_and_Games]", 528218, "3.21%"],
				["[Grocery_and_Gourmet_Food]", 495283, "3.01%"],
				["[Luggage_and_Travel_Gear]", 440361, "2.68%"],
				["[Musical_Instruments]", 331015, "2.01%"],
				["[Camera_and_Photo]", 323403, "1.97%"],
				["[CDs_and_Vinyl]", 295729, "1,80%"],
				["[Cellphones_and_Accessories]", 250861, "1.52%"],
				["[Baby]", 240037, "1.46%"],
				["[not found]", 203570, "1.24%"],
				["[Movies_and_TV]", 158197, "0.96%"],
				["[Video_Games]", 150170, "0.91%"],
				["[Pet_Supplies]", 103677, "0.63%"],
				["[Others]", 22771, "0.14%"]
			]);


			var view = new google.visualization.DataView(data);
			view.setColumns([0, 1,
				{
					calc: "stringify",
					sourceColumn: 1,
					type: "string",
					role: "annotation"
				}
			]);

			var options = {
				title: "Figure 4: Distribution of offer entities per category in the English product data corpus",
				width: 1000,
				height: 800,
				bar: {
					groupWidth: "75%"
				},
				legend: {
					position: "none"
				},
				hAxis: {
					title: '# Offer Entities',
					minValue: 0
				},
				vAxis: {
					title: 'Product Category',
					textStyle: {
						fontSize: 12
					}
				}
			};

			var chart = new google.visualization.BarChart(document.getElementById("catInCorpusOffers"));
			chart.draw(data, options);
		}


		function drawOffersPerClassChartEnglish() {

			var data = google.visualization.arrayToDataTable([
				["Offer Count", "Frequency(#ID-clusters)", {
					role: 'annotation'
				}],
				["[>80]", 3999, 113935797],
				["[71-80]", 682, 1899880],
				["[61-70]", 832, 1750014],
				["[51-60]", 1300, 1972822],
				["[41-50]", 2504, 2502691],
				["[31-40]", 4461, 2646306],
				["[21-30]", 10567, 3185935],
				["[11-20]", 37562, 3751124],
				["[5-10]", 163356, 3064532],
				["[3-4]", 400522, 1552680],
				["[2]", 1012220, 1012220]

			]);

			var view = new google.visualization.DataView(data);


			var options = {
				title: "Figure 2: Distribution of offers (bar label: #positive pairs) per ID-cluster - English Subset",
				width: 400,
				height: 400,
				bar: {
					groupWidth: "95%"
				},
				legend: {
					position: "none"
				},
				hAxis: {
					title: 'Frequency(#ID-clusters)',
					minValue: 0
				},
				vAxis: {
					title: '# Offers'
				}
			};

			var chart = new google.visualization.BarChart(document.getElementById("offersPerClass_english"));
			chart.draw(view, options);
		}

		function drawKVpairPerSpecTable() {

			var data = google.visualization.arrayToDataTable([
				["Key-Value Pairs Count", "Frequency(#Specification Tables)", {
					role: 'annotation'
				}],
				["[>30]", 9626, "0.3%"],
				["[27-30]", 9950, "0.3%"],
				["[24-26]", 26972, "0.8%"],
				["[21-23]", 88747, "2.7%"],
				["[18-20]", 112732, "3.4%"],
				["[14-17]", 198421, "6.1%"],
				["[11-13]", 402249, "12.4%"],
				["[7-10]", 514938, "15.9%"],
				["[4-6]", 659511, "20.3%"],
				["[1-3]", 47967, "1.4%"]
			]);


			var view = new google.visualization.DataView(data);

			view.setColumns([0, 1,
				{
					calc: "stringify",
					sourceColumn: 2,
					type: "string",
					role: "annotation"
				}
			]);

			var options = {
				title: "Figure 5: Distribution of key-value pairs per Specification Table",
				width: 600,
				height: 400,
				bar: {
					groupWidth: "75%"
				},
				legend: {
					position: "none"
				},
				hAxis: {
					title: 'Frequency(#Specification Tables)',
					minValue: 0
				},
				vAxis: {
					title: '# Key Value Pairs',
					textStyle: {
						fontSize: 12
					}
				}
			};


			var chart = new google.visualization.BarChart(document.getElementById("keyvaluespairs"));
			chart.draw(view, options);
		}

		function openExpResult(evt, expName) {
			// Declare all variables
			var i, tabcontent, tablinks;

			// Get all elements with class="tabcontent" and hide them
			tabcontent = document.getElementsByClassName("tabcontent");
			for (i = 0; i < tabcontent.length; i++) {
				tabcontent[i].style.display = "none";
			}

			// Get all elements with class="tablinks" and remove the class "active"
			tablinks = document.getElementsByClassName("tablinks");
			for (i = 0; i < tablinks.length; i++) {
				tablinks[i].className = tablinks[i].className.replace(" active", "");
			}

			// Show the current tab, and add an "active" class to the button that opened the tab
			document.getElementById(expName).style.display = "block";
			evt.currentTarget.className += " active";
		}
	</script>
	<script type="text/javascript" src="http://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
	<script type="text/javascript" src="../../jquery.toc.min.js"></script>
	<script type="text/javascript">
		var _gaq = _gaq || [];
		_gaq.push(['_setAccount', 'UA-30248817-1']);
		_gaq.push(['_trackPageview']);

		(function () {
			var ga = document.createElement('script');
			ga.type = 'text/javascript';
			ga.async = true;
			ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
			var s = document.getElementsByTagName('script')[0];
			s.parentNode.insertBefore(ga, s);
		})();
	</script>
	<script type="application/ld+json">
		{
			"@context": "http://schema.org/",
			"@type": "Dataset",
			"name": "Web Data Commons - The WDC Product Corpus and Gold Standard for Large-Scale Product Matching",
			"description": "The product dataset consists of 20 million pairs of product offers referring to the same products. The offers were extracted from 43 thousand e-shops which provide schema.org annotations including some form of product ID such as a GTIN or MPN. We also created a gold standard by manually verifying 4400 pairs of offers belonging to four different product categories.",
			"url": "http://webdatacommons.org/largescaleproductcorpusv2/index.html",
			"keywords": [
				"training corpus",
				"product corpus",
				"large scale",
				"product matching",
				"entity matching"
			],
			"creator": [
				{
					"@type": "Person",
					"url": "http://dws.informatik.uni-mannheim.de/en/people/researchers/anna-primpeli/",
					"name": "Anna Primpeli"
				},
				{
					"@type": "Person",
					"url": "http://dws.informatik.uni-mannheim.de/en/people/researchers/ralph-peeters/"
					"name": "Ralph Peeters"
				},
				{
					"@type": "Person",
					"url": "http://dws.informatik.uni-mannheim.de/en/people/professors/prof-dr-christian-bizer/",
					"name": "Christian Bizer"
				}
			],
			"distribution": [{
				"@type": "DataDownload",
				"fileFormat": [
					"json"
				],
				//TODO: Change once final
				"contentUrl": "http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/offers.json.gz"
			}],
			"citation": [

			]
		}
	</script>

</head>

<body>
	<div id="logo" style="text-align:right; background-color: white;">&nbsp;&nbsp;<a
			href="http://dws.informatik.uni-mannheim.de"><img src="../../images/ma-logo.gif"
				alt="University of Mannheim - Logo"></a></div>
	<div id="header">
		<h1 style="font-size: 250%;">WDC Product Data Corpus and Gold Standard for Large-Scale Product Matching -
			Version 2.0</h1>
	</div>
	<div id="authors">
		<a href="https://www.uni-mannheim.de/dws/people/researchers/phd-students/ralph-peeters/">Ralph Peeters</a><br>
		<a href="https://www.uni-mannheim.de/dws/people/researchers/phd-students/anna-primpeli/">Anna Primpeli</a><br />
		<a href="https://www.uni-mannheim.de/dws/people/professors/prof-dr-christian-bizer/">Christian Bizer</a><br />

	</div>
	<div id="content">
		<p>
			This page provides <strong>Version 2.0</strong> of the WDC Product Data Corpus and Gold Standard for
			Large-scale Product Matching for public download.
			The product data corpus consists of 26 million product offers originating from 79 thousand websites. The
			offers are grouped into 16 million clusters of offers referring to the same product using product
			identifiers, such
			as GTINs or MPNs. The gold standard consists of 4,400 pairs of offers that were manually verified as matches
			or non-matches. For easing the comparison of supervised matching methods, we also provide several
			pre-assembled training and validation sets for download (ranging from 9,000 and 214,000 pairs of
			offers).<br>
		</p>
		<h2 id="news">News</h2>
		<ul>
			<li><strong>2020-11-19:</strong> The Product Matching Task (Task 1) of the <a href="https://ir-ischool-uos.github.io/mwpd/">MWPD Semantic Web Challenge</a> presented at <a href="https://iswc2020.semanticweb.org/">ISWC2020</a> was based on this data corpus. The <a href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/swc/task1_testset_1500_with_labels.json.gz">new test set</a> used for evaluating the system submissions as well as the <a href="http://ceur-ws.org/Vol-2720/">summary and system papers</a> (including results) of the challenge are now available.</li>
			<li><strong>2020-08-24:</strong> The paper <a href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/papers/DI2KG2020_Peeters.pdf">Intermediate Training of BERT for Product Matching</a> using Version 2.0 of the corpus has been accepted at the <a href="http://di2kg.inf.uniroma3.it/2020/#">DI2KG workshop</a> held in conjunction with <a href="https://vldb2020.org/">VLDB2020</a>.</li>
			<li><strong>2020-07-01:</strong> We will present the paper <a href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/papers/WIMS2020_Peeters.pdf">Using schema.org Annotations for Training and Maintaining Product Matchers</a> using Version 2.0 of the corpus at the <a href="https://wims2020.sigappfr.org/pp/">WIMS2020</a> conference.</li>
			<li><strong>2020-03-19:</strong> The <a href="http://www.wikicfp.com/cfp/servlet/event.showcfp?eventid=100326">CfP</a> for the <a href="https://ir-ischool-uos.github.io/mwpd/">Semantic Web Challenge</a>@<a href="https://iswc2020.semanticweb.org/">ISWC2020</a> "Mining the Web of HTML-embedded Product Data" has been announced. The <a href="http://webdatacommons.org/largescaleproductcorpus/v2/index.html">WDC Product Data Corpus and Gold Standard V2.0</a> will be used as training and evaluation resources for the Product Matching task.

			<li><strong>2019-10-23:</strong> Version 2.0 of the WDC product data corpus, gold standard, and training
				sets released.</li>
			<li><strong>2019-08-19:</strong> We have <a
					href="http://webdatacommons.org/categorization/index.html">updated the product categorization</a>
				within the English subset of the WDC product data corpus.</li>
			<li><strong>2019-05-04:</strong> A paper about the <a href="https://www.uni-mannheim.de/media/Einrichtungen/dws/Files_Research/Web-based_Systems/pub/ECNLP_19_PrimpeliPeetersBizer.pdf"> WDC
					Training Dataset and Gold Standard for Large-Scale Product Matching</a> was presented at <a
					href="https://sites.google.com/view/ecnlp/home">ECNLP2019</a> workshop in San Francisco.</li>
			<li><strong>2018-12-19:</strong> <a href="http://webdatacommons.org/largescaleproductcorpus/">Initial
					version</a> of the product data corpus, gold standard, and training dataset released.</li>
		</ul>
		<h2>Contents</h2>
		<ul>
			<li class="toc-h2 toc-active">
				<a href="#toc1"> 1 Introduction</a>
			</li>
			<li class="toc-h2 toc-active">
				<a href="#toc2"> 2 Product Data Corpus</a>
				<ul>
					<li><a href="#toc2.1"> 2.1 Profile of the Corpus</a>
					</li>
					<li><a href="#toc2.2"> 2.2 Schema of the Corpus</a> </li>
				</ul>
			</li>
			<li class="toc-h2 toc-active">
				<a href="#toc3"> 3 Gold Standard</a>
				<ul>
					<li><a href="#toc3.1">3.1 Product and Pair Selection</a></li>
					<li><a href="#toc3.2">3.2 Profile of the Gold Standard</a></li>
				</ul>
			</li>
			<li class="toc-h2 toc-active">
				<a href="#toc4"> 4 Training Sets</a>
				<ul>

					<li><a href="#toc4.1">4.1 Pair Selection</a></li>
					<li><a href="#toc4.2">4.2 Profile of the Training Sets</a></li>
				</ul>
			</li>
			<li class="toc-h2 toc-active">
				<a href="#toc5"> 5 Baseline Experiments</a>
				<ul>
					<li><a href="#toc5.1">5.1 Experimental Setup</a></li>
					<li><a href="#toc5.2">5.2 Results</a></li>
				</ul>
			</li>
			<li class="toc-h2 toc-active">
				<a href="#toc6"> 6 Download </a>
			</li>
			<li class="toc-h2 toc-active">
				<a href="#toc7"> 7 Feedback </a>
			<li class="toc-h2 toc-active"><a href="#toc8">8 References </a>
			</li>
		</ul>

		<span id="toc1"></span>
		<h2>1 Introduction</h2>
		<p>The research focus in the field of identity resolution (also called duplicate detection or link discovery) is
			moving from
			traditional symbolic matching methods towards embeddings and deep neural network based matching methods. The
			problem with
			evaluating deep learning based matchers is that they require large amounts of training data for playing
			their strengths. The benchmark datasets
			that have been used so far for comparing matching methods are often too small to properly evaluate this new
			family
			of methods. Another problem with existing benchmark datasets is that they are mostly based on data from a
			small set
			of data sources and thus do not properly reflect the heterogeneity that is found in large-scale integration
			scenarios. The WDC gold standard and training sets for large-scale product matching tackle both
			challenges by being derived from a large product data corpus originating from many websites which annotate
			product descriptions using the schema.org vocabulary. We have performed a set of experiments in order to showcase the suitability of the WDC product corpus 
			as training data as well as the difficulty of the gold standard. The experiments show that deep learning based matchers reach an F1 of 0.90 
			using the xlarge training set and outperform traditional symbolic matchers by a margin of 16% in F1. </p>
			<span id="toc2"></span>
		<h2>2 Product Data Corpus </h2>
		<p>Many e-shops mark-up <a href="https://schema.org/Product">products</a> and <a
				href="https://schema.org/Offer">offers</a> within their HTML pages using the <a
				href="https://schema.org/" target="_blank">schema.org</a>
			vocabulary. In recent years, many e-shops have also started to annotate product identifiers such as
			<i>gtin8, gtin13,
				gtin14,</i> <i>mpn</i> and <i>sku</i>.
			These identifiers allow offers for the same product from different e-shops to be grouped into clusters and
			can thus
			be used as supervision for training product matching methods. </p>
		<p>The <a href="http://webdatacommons.org/structureddata/">Web Data Commons project</a> regularly extracts
			schema.org annotations from the <a href="https://commoncrawl.org/">Common Crawl</a>, a large public web
			corpus. <a href="http://webdatacommons.org/structureddata/2017-12/stats/schema_org_subsets.html">November
				2017 version</a> of the WDC schema.org data set contains 365 million offers. The WDC Product Data Corpus
			was derived from this dataset using a cleansing workflow which ignores offers on list pages and only keeps
			offers annotating interpretable product identifiers. The different steps of the cleansing workflow are
			described in detail <a href="http://webdatacommons.org/largescaleproductcorpus/">here</a> and in [<a
				href="#PrPeBi2019">PrimpeliPeetersBizer2019</a>]. </p>
				<span id="toc2.1"></span>
		<h3>2.1 Corpus Profiling</h3>
		<p>The resulting Full Product Corpus consists of 26 million offers originating
			from 79 thousand websites. Using the product identifiers, the offers are grouped into 16 million clusters.
			We also assemble an English subset of the product data corpus which only includes offers from English-related
			top-level domains (TLDs): <i>com</i>, <i>net</i>, <i>co.uk</i>, <i>us</i>, and <i>org</i>. The English
			subset contains 16 million
			offers originating from 43 thousand websites. The offers are grouped into 10 million ID-clusters.
			The charts below show the distribution of the size of the ID-clusters in the overall corpus and in the
			English subset, as well as the distribution of the offers by top-level domain. </p>
		<div>
			<span id="offersPerClass" style="float:left"></span>
			<span id="offersPerClass_english" style="float:left"></span>
			<span id="offersPerTLD" style="float:left"></span>
		</div>


		<p style="clear:both">

			We learn a classifier for assigning each offer to one of 25 top-level product categories.
			The resulting distribution of offers per category in the English product corpus is shown in Figure 4.
			You can find more information about the categorisation process and its evaluation <a
				href="http://webdatacommons.org/categorization/index.html">here</a>.
			We also extract key/value-pairs from the product specification tables that may exist on the offer pages.
			Using the specification table detection methods described <a
				href="http://webdatacommons.org/largescaleproductcorpus/#toc3">here</a>, we extract specification tables
			from 3.2 million webpages (17% of all pages of the Full Product Corpus). </p>

		<div>
			<span id="catInCorpusOffers" style="float:left"></span>
		</div>
		<h2></h2>
		<span id="toc2.2"></span>
		<h3 style="clear:both">2.2. Schema of the Corpus</h3>
		
		<p>
			The offers in version 2.0 of the product data corpus is described by the attributes listed below. Please note that compared to  <a href="http://webdatacommons.org/largescaleproductcorpus/index.html">version 1.0</a> of the corpus, the identification schema was simplified while the actual content stayed exactly the same.
		</p>
		<p>
				<ul>
						<li><strong> id:</strong> Unique integer identifier of an offer </li>
						<li><strong> cluster_id:</strong> The integer ID of the cluster to which an offer belongs. </li>
						<li><strong> identifiers:</strong> A list of all identifier values that were assigned to an offer
							together with
							the schema.org terms that were used to annotate the values. </li>
							<ul>
								<li>'[{'/sku': '[34852050]'}, {'/mpn': '[f5e10c10m10]'}]'</li>
								<li>'[{'/productID': '[9781441870148]'},
										{'/sku': '[bkbrll003023]'},
										{'/gtin13': '[9781441870148]'}]'</li>
							</ul>
						<li><strong> category:</strong> One of 25 product categories the product was assigned to, NaN if not
							part of the English subset</li>
							<ul>
									<li>'Computers_and_Accessories'</li>
									<li>'Office_Products'</li>
								</ul>
						<li><strong> title: </strong>The product title</li>
						<ul><strong> Non-Normalized </strong>
								<li>'AMD YD1400BBAEBOX Ryzen 1400 3.2g 8mb 65w Wraith Stealth Cooler for $169.80'</li>
								<li>'Corsair Vengeance Red LED 16GB 2x 8GB DDR4 PC4 21300 2666Mhz dual-channel Kit - CMU16GX4M2A2666C16R Novatech'</li>
						</ul>
						<ul><strong> Normalized </strong>
								<li>'amd yd1400bbaebox ryzen 5 1400 3 2g 8mb 65w with wraith stealth cooler for 169 80'</li>
								<li>'corsair vengeance red led 16gb 2x8gb ddr4 pc4 21300 2666mhz dual channel kit cmu16gx4m2a2666c16r novatech'</li>
							</ul>
						
						<li><strong> description: </strong>The product description</li>
						<ul><strong> Non-Normalized </strong>
								<li>'AMD YD1400BBAEBOX Ryzen 1400 3.2g 8mb 65w Wraith Stealth Cooler for $169.80. Free shipping on large orders. 30 day return policy. Secure purchasing. Highly rated company established 1991.'</li>
								<li>'DDR4 2666MHz C116, 1.2V, XMP 2.0 red-led, Lifetime Warranty'</li>
							</ul>
						<ul><strong> Normalized </strong>
								<li>'amd yd1400bbaebox ryzen 1400 3 2g 8mb 65w wraith stealth cooler for 169 80 free shipping on large orders 30 day return policy secure purchasing highly rated company established 1991'</li>
								<li>'ddr4 2666mhz cl16 1 2v xmp 2 0 red led lifetime warranty'</li>
							</ul>
							
						<li><strong> brand: </strong>The product brand</li>
						<ul><strong> Non-Normalized </strong>
								<li>'AMD'</li>
								<li>'Corsair'</li>
							</ul>
						<ul><strong> Normalized </strong>
								<li>'amd'</li>
								<li>'corsair'</li>
							</ul>
						
						<li><strong> price: </strong>The product price</li>
						<ul><strong> Non-Normalized </strong>
								<li>'USD 169.95'</li>
								<li>'USD 89.99'</li>
							</ul>
						<ul><strong> Normalized </strong>
								<li>'usd 169 95'</li>
								<li>'usd 89 99'</li>
							</ul>
							
						<li><strong> specTableContent: </strong>The specification table content of the products website as
							one string</li>
							<ul> <strong> Non-Normalized </strong>
									<li>'Mfg. & Model: AMD YD1400BBAEBOX Mfg. Part #: YD1400BBAEBOX UPC: 730143308427 Description: Ryzen 5 1400 3.2g 8mb 65w With Wraith Stealth Cooler Price: $169.80 Essential Information BLT Item #: B8Q6824 Manufacturer Part #: YD1400BBAEBOX Manufacturer: AMD Description: RYZEN 5 1400 3.2G 8MB 65W WITH WRAITH STEALTH COOLER Weight: 1.1 lbs. Manufacturer's website: http://www.amd.com/ Dimensions: 5.4\" x 5.4\" x 5.3\" UPC: 730143308427 Return Policy: Standard BLT Return Policy'</li>
									<li>'Memory Type DDR4 (PC4-21300) Capacity 16GB (2 x 8GB) Tested Speed 2666MHz Tested Latency 16-18-18-35 Tested Voltage 1.20V Registered / Unbuffered Unbuffered Error Checking Non-ECC Memory Features - red-led XMP 2.0'</li>
								</ul>
							<ul> <strong> Normalized </strong>
									<li>'mfg model amd yd1400bbaebox mfg part yd1400bbaebox upc 730143308427 description ryzen 5 1400 3 2g 8mb 65w with wraith stealth cooler price 169 80 essential information blt item b8q6824 manufacturer part yd1400bbaebox manufacturer amd description ryzen 5 1400 3 2g 8mb 65w with wraith stealth cooler weight 1 1 lbs manufacturer s website http www amd com dimensions 5 4 x 5 4 x 5 3 upc 730143308427 return policy standard blt return policy'</li>
									<li>'memory type ddr4 pc4 21300 capacity 16gb 2 x 8gb tested speed 2666mhz tested latency 16 18 18 35 tested voltage 1 20v registered unbuffered unbuffered error checking non ecc memory features red led xmp 2 0'</li>
								</ul>
							
						<li><strong> keyValuePairs: </strong>The key-value pairs that were extracted from the specification tables using the method described above</li>
						<ul><strong> Non-Normalized </strong>
								<li>'{'Mfg. & Model:':'AMD YD1400BBAEBOX',
									'Mfg. Part #:':'YD1400BBAEBOX',
									'UPC:':'730143308427',
									'Description:':'RYZEN 5 1400 3.2G 8MB 65W WITH WRAITH STEALTH COOLER',
									'Price:':'$169.80',
									'BLT Item #:':'B8Q6824',
									'Manufacturer Part #:':'YD1400BBAEBOX',
									'Manufacturer:':'AMD',
									'Weight:':'1.1 lbs.',
									'Manufacturer's website:':'http://www.amd.com/',
									'Dimensions:':'5.4\" x 5.4\" x 5.3\"',
									"Return Policy:":"Standard BLT Return Policy'}'</li>
								<li>
									'{'Memory Type':'DDR4 (PC4-21300)',
									'Capacity':'16GB (2 x 8GB)',
									'Tested Speed':'2666MHz',
									'Tested Latency':'16-18-18-35',
									'Tested Voltage':'1.2V',
									'Registered / Unbuffered':'Unbuffered',
									'Error Checking':'Non-ECC',
									'Memory Features':'red-led XMP 2.0'}'
								</li>
							</ul>
						
						<ul><strong> Normalized </strong>
								<li>'{'mfg model': 'amd yd1400bbaebox',
										'mfg part': 'yd1400bbaebox',
										'upc': '730143308427',
										'description': 'ryzen 5 1400 3 2g 8mb 65w with wraith stealth cooler',
										'price': '169 80',
										'blt item': 'b8q6824',
										'manufacturer part': 'yd1400bbaebox',
										'manufacturer': 'amd',
										'weight': '1 1 lbs',
										'manufacturer s website': 'http www amd com',
										'dimensions': '5 4 x 5 4 x 5 3',
										'return policy': 'standard blt return policy'}'</li>
								<li>'{'memory type': 'ddr4 pc4 21300',
										'capacity': '16gb 2 x 8gb',
										'tested speed': '2666mhz',
										'tested latency': '16 18 18 35',
										'tested voltage': '1 20v',
										'registered unbuffered': 'unbuffered',
										'error checking': 'non ecc',
										'memory features': 'red led xmp 2 0'}'</li>
							</ul>
							
					</ul>

		</p>
		<!--
		<p>
			<ul>
				<li>title - if the schema.org attribute <i>title</i> exists, we use it and add all non-contained tokens
					from the schema.org <i>name</i> attribute
					as well as the parent <i>title</i> and <i>name</i> attributes in an iterative fashion resulting in
					one title containing all the information from the schema.org attributes.
					Should the first attribute be empty, then we take the full string from the next attribute in line
					and continue adding the missing tokens from the following attributes.
					schema.org name and title properties are both used for the title attribute, as they are used for the
					same purpose. Precedence is given to the schema.org title attribute
					as it is the most frequently filled one.</li>

				<li>description - if the schema.org attribute <i>description</i> exists, we use it and add all
					non-contained tokens from the parent <i>description</i> attribute resulting in one description
					containing all the information from the schema.org attributes.
					Should the first attribute be empty, then we take the full string from the parent attribute.</li>

				<li>brand - if the schema.org attribute <i>brand</i> exists, we select it, otherwise we use the
					<i>manufacturer</i> attribute. If both do not exist, then the corresponding parent attributes are
					checked and the first filled one is selected.
				</li>
				<li>price - if the schema.org attribute <i>price</i> exists, we select it, otherwise we use the parent
					attribute. Only if one of the two attributes exists we further concatenate either the priceCurrency
					(if it exists) or the parent priceCurrency attributes
				</li>
				<li>specTableContent and keyValuePairs - directly added to the datasets from the corresponding files and
					preprocessed in the same way as the other attributes were during the building of the product corpus.
				</li>
			</ul>
		</p>
		<p>
			After performing these steps all attributes but the ones mentioned in the beginning of this paragraph are
			dropped.
		</p>
		-->
		<span id="toc3"></span>
		<h2>3 Gold Standard</h2>
		<p>
			We derive a gold standard for evaluating product matching methods from the English product data corpus. The
			gold standard consists of 1100 pairs of offers from each of the following four product categories:
			<em>Computers & Accessories</em>, <em>Camera & Photo</em>,
			<em>Watches,</em> and <em>Shoes</em>. The gold standard covers 150 products (ID-clusters) from each
			category. For each product, the gold standard contains 2 matching pairs of offers (positives) and 5 or 6
			non-matching pairs of offers (negatives). All pairs of offers were manually reviewed. We provide the gold
			standards for <a href="#toc7">download</a>
			at the bottom of the page. </p>
		<p>We aimed at including a diverse selection of products as well as a good mixture of difficult and easy to
			match pairs of offers into the gold standard. Below, we describe the method that we used for selecting
			products and offer pairs and provide some statistics about the profile of the gold standard.</p>
			<span id="toc3.1"></span>
		<h3>3.1 Product and Pair Selection</h3>
		<p> We randomly select 150 ID-Clusters
			per category.
			For each of the 150 products, we want a good mixture of difficult and easy to match positive and negative
			pairs of offers in the gold standard. For determining which pairs to include, we apply the following
			heuristic: 
		</p>
		<p>For each product (ID-cluster), we select two positive pairs from inside a cluster. All possible pairs inside a cluster are ordered using Jaccard similarity of the titles, Jaccard similarity of the
			descriptions, or using the average of both (the selected metric is chosen randomly).
			We then select one hard pair by taking the most dissimilar pair (likely difficult pair close to decision boundary) and choose the second positive randomly from the list (likely easy pair).</p>
		<p>
			To select negatives we select one offer from the current cluster and build all possible pairs with all offers from the same category. After applying one of the mentioned similarities at random we
			order the resulting list of pairs and select two to three negative pairs with a high similarity (likely also difficult pairs) and
			three randomly chosen negative pairs (likely easy pairs) from that list.
			We manually
			verify
			that the selected pairs are really matches or non-matches by reading the titles
			and descriptions of the offers. </p>
		</p>
		<span id="toc3.2"></span>
		<h3>3.2 Gold Standard Profile
		</h3>
		<p>The resulting gold standard datasets consist of 300 positive and 800 negative
			pairs of offers from each category. The title attribute
			of all of these offers is filled. The other attributes describing the offers might contain NULL values and
			thus have a lower density. Table 1 shows the percentage of pairs per
			category where both offers contain a value for the respective attribute.</p>
		<table class="smalltable" style="margin-top:2em">
			<caption>
				<p>
					Table 1: Gold standard statistics per category
				</p>
			</caption>
			<thead>
				<tr>
					<th>Category</th>
					<th># positive pairs</th>
					<th># negative pairs</th>
					<th>% title</th>
					<th>% description</th>
					<th>% brand</th>
					<th>% price</th>
					<th>% specTableContent</th>
				</tr>
			</thead>
			<tbody>
				<tr>
					<td>Computers</td>
					<td>300</td>
					<td>800</td>
					<td>100</td>
					<td>82</td>
					<td>42</td>
					<td>11</td>
					<td>22</td>
				</tr>
				<tr>
					<td>Cameras</td>
					<td>300</td>
					<td>800</td>
					<td>100</td>
					<td>73</td>
					<td>25</td>
					<td>3</td>
					<td>7</td>
				</tr>
				<tr>
					<td>Watches</td>
					<td>300</td>
					<td>800</td>
					<td>100</td>
					<td>71</td>
					<td>15</td>
					<td>1</td>
					<td>7</td>
				</tr>
				<tr>
					<td>Shoes</td>
					<td>300</td>
					<td>800</td>
					<td>100</td>
					<td>70</td>
					<td>8</td>
					<td>1</td>
					<td>2</td>
				</tr>
				<tr>
					<td><strong>All</strong></td>
					<td><strong>1200</strong></td>
					<td><strong>3200</strong></td>
					<td><strong>100</strong></td>
					<td><strong>74</strong></td>
					<td><strong>23</strong></td>
					<td><strong>4</strong></td>
					<td><strong>10</strong></td>
				</tr>
			</tbody>
		</table>

		<p>Altogether the gold standard consists of offers for 2485 products (ID-clusters). These offers are
			distributed as follows over the product categories: 745 for Computers
			& Accessories, 563 for Camera & Photo, 617 for Watches and 563 for Shoes. Positive pairs exist for 150 of
			these products per category. The remaining products are used to build negative pairs (see sampling process
			above). </p>
			<span id="toc4"></span>
		<h2>4 Training Sets </h2>
		<p>
			The offers in the WDC product data corpus that share identifiers (ID-clusters) can be used as weak
			supervision for training product matching methods. There are manifold possibilities on how to derive training sets of different
			size from the WDC product data corpus. In order to allow the comparison of supervised matching
			methods using the same training and validation sets, we offer pre-assembled training and validation sets of
			4 sizes for <a href="#toc7">download</a>. The training sets were derived from the same 2485 ID-clusters that
			are also used by the gold standard. In the following, we describe how we selected pairs of offers from the
			clusters into the training sets. Afterwards, we provide statistics about the training sets.<br>
			<h3></h3>
			<span id="toc4.1"></span>
			<h3>4.1 Pair Selection</h3>
			<p>Before selecting pairs, we perform the following cleaning steps in order to allow the selection of varied
				and good pairs. Within each cluster, we
				<ul>
					<li>drop all offers that have no title,</li>
					<li>keep only one offer of those with duplicate titles at random,</li>
					<li>if the concatenation of title and description contains less then 5 tokens, the offer is dropped.
					</li>
				</ul>

				<p>To generate the <strong>positive pairs</strong> of the training set, we iterate over all clusters.
					For each cluster, we build all combinations of offers inside the cluster and from this pool randomly
					sample x positive pairs. x can be used as a scaling factor to vary the amount of positive pairs sampled per product. If the pool contains less than
					x pairs, the maximum amount possible is sampled. For each pair it is assured that it does not appear
					in the corresponding gold standard. We also
					only allow half of the pairs to have a title that also appears in the gold standard. <br>
					<br>
					To build <strong>negative pairs</strong>, in a first step, the title similarity of all pairs of
					clusters from
					the gold standard is calculated using Jaccard similarity over the concatenated
					titles of all offers within a cluster. In a second step, for each cluster, the top ten most similar
					clusters based
					on this similarity are chosen. Considering the resulting ten pairs of clusters (current cluster and
					10 most similar clusters),
					the smallest of the ten similar clusters is selected and the other 9 are randomly downsampled to the
					same size. Then all possible pairs between each combination of the ten similar clusters
					with the current cluster are built. From the resulting pool, y negative pairs are randomly sampled.
					y again is a scaling factor. If the pool contains less than y pairs, the maximum amount possible is
					sampled.
					Once again it is ensured, that only half of these pairs contain titles that appear in the gold
					standard. If during the selection of the ten most similar clusters
					negative pairs between these clusters already exist due to prior sampling for the other cluster,
					this cluster combination does not contribute further pairs to the pool.
					This procedure for sampling negative pairs ensures that the offers within a negative pair are rather
					similar and thus likely interesting for learning good classifiers. <br>
					<br>
				</p>
				<span id="toc4.2"></span>
				<h3>4.2 Profile of the Training Sets</h3>
				<p>By varying the scaling factors x and y it is possible to create training sets of different sizes. We
					decide on a fixed positives/negatives ratio of 1:3 for x:y and build four training sets of increasing
					size for the values: 1:3, 3:9, 15:45 and 50:150.
					Table 2 shows the statistics about the size and attribute density of the resulting training sets.
					Figure 5 shows the distributions of training examples over the clusters for positives, negatives and
					combined training sets for computers, cameras, watches and shoes respectively.
					We see that for some products, it is not possible to sample the desired amounts of pairs due to
					small clusters or due to the
					aforementioned cleaning steps.</p>
			</p>
			<table class="smalltable" style="float: left;margin-right:5.0em">
				<caption>
					<p><strong>Table 2: Small Training Set 1:3 </strong> (Number of Pairs and Attribute Densities)</p>
				</caption>
				<thead>
					<tr>
						<th>Category</th>
						<th># products</th>
						<th># positive</th>
						<th># negative</th>
						<th># combined</th>
						<th>% title</th>
						<th>% description</th>
						<th>% brand</th>
						<th>% price</th>
						<th>% specTableContent</th>
					</tr>
				</thead>
				<tbody>
					<tr>
						<td>Computers</td>
						<td>745</td>
						<td>722</td>
						<td>2112</td>
						<td>2834</td>
						<td>100</td>
						<td>51</td>
						<td>34</td>
						<td>5</td>
						<td>21</td>
					</tr>
					<tr>
						<td>Cameras</td>
						<td>561</td>
						<td>486</td>
						<td>1400</td>
						<td>1886</td>
						<td>100</td>
						<td>53</td>
						<td>21</td>
						<td>1</td>
						<td>4</td>
					</tr>
					<tr>
						<td>Watches</td>
						<td>615</td>
						<td>580</td>
						<td>1675</td>
						<td>2255</td>
						<td>100</td>
						<td>43</td>
						<td>15</td>
						<td>0</td>
						<td>7</td>
					</tr>
					<tr>
						<td>Shoes</td>
						<td>562</td>
						<td>530</td>
						<td>1533</td>
						<td>2063</td>
						<td>100</td>
						<td>49</td>
						<td>8</td>
						<td>2</td>
						<td>0</td>
					</tr>
					<tr>
						<td><strong>All</strong></td>
						<td><strong>2480</strong></td>
						<td><strong>2318</strong></td>
						<td><strong>6720</strong></td>
						<td><strong>9038</strong></td>
						<td><strong>100</strong></td>
						<td><strong>49</strong></td>
						<td><strong>21</strong></td>
						<td><strong>2</strong></td>
						<td><strong>10</strong></td>
					</tr>
				</tbody>
			</table>
			<table class="smalltable" style="float: left;margin-right:5.0em">
				<caption>
					<p><strong>Table 3: Medium </strong><strong>Training Set 3:9</strong> (Number of Pairs and Attribute
						Densities)</p>
				</caption>
				<thead>
					<tr>
						<th>Category</th>
						<th># products</th>
						<th># positive</th>
						<th># negative</th>
						<th># combined</th>
						<th>% title</th>
						<th>% description</th>
						<th>% brand</th>
						<th>% price</th>
						<th>% specTableContent</th>
					</tr>
				</thead>
				<tbody>
					<tr>
						<td>Computers</td>
						<td>745</td>
						<td>1762</td>
						<td>6332</td>
						<td>8094</td>
						<td>100</td>
						<td>51</td>
						<td>34</td>
						<td>5</td>
						<td>20</td>
					</tr>
					<tr>
						<td>Cameras</td>
						<td>562</td>
						<td>1108</td>
						<td>4147</td>
						<td>5255</td>
						<td>100</td>
						<td>57</td>
						<td>22</td>
						<td>1</td>
						<td>4</td>
					</tr>
					<tr>
						<td>Watches</td>
						<td>615</td>
						<td>1418</td>
						<td>4995</td>
						<td>6413</td>
						<td>100</td>
						<td>44</td>
						<td>14</td>
						<td>0</td>
						<td>6</td>
					</tr>
					<tr>
						<td>Shoes</td>
						<td>562</td>
						<td>1214</td>
						<td>4591</td>
						<td>5805</td>
						<td>100</td>
						<td>49</td>
						<td>7</td>
						<td>1</td>
						<td>0</td>
					</tr>
					<tr>
						<td><strong>All</strong></td>
						<td><strong>2481</strong></td>
						<td><strong>5502</strong></td>
						<td><strong>20065</strong></td>
						<td><strong>25567</strong></td>
						<td><strong>100</strong></td>
						<td><strong>50</strong></td>
						<td><strong>20</strong></td>
						<td><strong>2</strong></td>
						<td><strong>9</strong></td>
					</tr>
				</tbody>
			</table>
			<table class="smalltable" style="float: left;margin-right:5.0em">
				<caption>
					<p><strong>Table 4: Large </strong><strong>Training Set 14:45</strong> (Number of Pairs and
						Attribute Densities)</p>
				</caption>
				<thead>
					<tr>
						<th>Category</th>
						<th># products</th>
						<th># positive</th>
						<th># negative</th>
						<th># combined</th>
						<th>% title</th>
						<th>% description</th>
						<th>% brand</th>
						<th>% price</th>
						<th>% specTableContent</th>
					</tr>
				</thead>
				<tbody>
					<tr>
						<td>Computers</td>
						<td>745</td>
						<td>6146</td>
						<td>27213</td>
						<td>33359</td>
						<td>100</td>
						<td>51</td>
						<td>31</td>
						<td>5</td>
						<td>18</td>
					</tr>
					<tr>
						<td>Cameras</td>
						<td>561</td>
						<td>3843</td>
						<td>16193</td>
						<td>20036</td>
						<td>100</td>
						<td>60</td>
						<td>25</td>
						<td>2</td>
						<td>3</td>
					</tr>
					<tr>
						<td>Watches</td>
						<td>616</td>
						<td>5163</td>
						<td>21864</td>
						<td>27027</td>
						<td>100</td>
						<td>45</td>
						<td>13</td>
						<td>0</td>
						<td>6</td>
					</tr>
					<tr>
						<td>Shoes</td>
						<td>562</td>
						<td>3482</td>
						<td>19507</td>
						<td>22989</td>
						<td>100</td>
						<td>51</td>
						<td>6</td>
						<td>1</td>
						<td>0</td>
					</tr>
					<tr>
						<td><strong>All</strong></td>
						<td><strong>2481</strong></td>
						<td><strong>18620</strong></td>
						<td><strong>84777</strong></td>
						<td><strong>103397</strong></td>
						<td><strong>100</strong></td>
						<td><strong>51</strong></td>
						<td><strong>19</strong></td>
						<td><strong>2</strong></td>
						<td><strong>8</strong></td>
					</tr>
				</tbody>
			</table>
			<table class="smalltable" style="float: left;margin-right:5.0em">
				<caption>
					<p><strong>Table 5: Extra Large Training </strong><strong>Set 50:10 </strong>(Number of Pairs and
						Attribute Densities)</p>
				</caption>
				<thead>
					<tr>
						<th>Category</th>
						<th># products</th>
						<th># positive</th>
						<th># negative</th>
						<th># combined</th>
						<th>% title</th>
						<th>% description</th>
						<th>% brand</th>
						<th>% price</th>
						<th>% specTableContent</th>
					</tr>
				</thead>
				<tbody>
					<tr>
						<td>Computers</td>
						<td>745</td>
						<td>9690</td>
						<td>58771</td>
						<td>68461</td>
						<td>100</td>
						<td>50</td>
						<td>30</td>
						<td>5</td>
						<td>16</td>
					</tr>
					<tr>
						<td>Cameras</td>
						<td>562</td>
						<td>7178</td>
						<td>35099</td>
						<td>42277</td>
						<td>100</td>
						<td>66</td>
						<td>29</td>
						<td>2</td>
						<td>3</td>
					</tr>
					<tr>
						<td>Watches</td>
						<td>615</td>
						<td>9264</td>
						<td>52305</td>
						<td>61569</td>
						<td>100</td>
						<td>50</td>
						<td>11</td>
						<td>0</td>
						<td>5</td>
					</tr>
					<tr>
						<td>Shoes</td>
						<td>562</td>
						<td>4141</td>
						<td>38288</td>
						<td>42429</td>
						<td>100</td>
						<td>53</td>
						<td>5</td>
						<td>0</td>
						<td>0</td>
					</tr>
					<tr>
						<td><strong>All</strong></td>
						<td><strong>2481</strong></td>
						<td><strong>30198</strong></td>
						<td><strong>184463</strong></td>
						<td><strong>214661</strong></td>
						<td><strong>100</strong></td>
						<td><strong>54</strong></td>
						<td><strong>19</strong></td>
						<td><strong>2</strong></td>
						<td><strong>7</strong></td>
					</tr>
				</tbody>
			</table>
				<figure style='float:left;margin-top:3em;' >
					<figcaption style='margin-bottom:1em;'><strong>Figure 5: Distribution of training examples over all 2481 products (ID-clusters) in the xlarge training set</strong></figcaption>
					<img src="images/computers/xlarge.png" width="938" height="350" style='margin-bottom:2em;'>
					<img src="images/cameras/xlarge.png" width="938" height="350" style='margin-bottom:2em;'>
					<img src="images/watches/xlarge.png" width="938" height="350" style='margin-bottom:2em;'>
						<img src="images/shoes/xlarge.png" width="938" height="350" style='margin-bottom:2em;'>
					
					</figure>
			</div>

			<div>
				<figure style='float:left;margin-top:3em'>
					<figcaption style='margin-bottom:1em;'><strong>Figure 6: Distribution of training samples in xlarge training set over the 150 products (ID-clusters) that have positives in the gold standard.</strong></figcaption>
					<img src="images/computers/150_selection.png" width="938" height="350" style='margin-bottom:2em;'>
					<img src="images/cameras/150_selection.png" width="938" height="350" style='margin-bottom:2em;'>
					<img src="images/watches/150_selection.png" width="938" height="350" style='margin-bottom:2em;'>
						<img src="images/shoes/150_selection.png" width="938" height="350" style='margin-bottom:2em;'>
					
					</figure>
			</div>
			<h2></h2>
			<span id="toc5"></span>
			<h2>5 Baseline Experiments</h2>
			
			<p>
				We have performed a set of experiments in order to showcase the
				suitability of the WDC product corpus as training data as well as the difficulty of the gold standard.
				These are:
			</p>
			<ol>
				<li>an unsupervised baseline experiment using TF/IDF and cosine similarity using different feature
					combinations.</li>
				<li>a supervised experiment using word co-occurrence between product features as classifier input.</li>
				<li>a supervised experiment using the <a
						href="https://sites.google.com/site/anhaidgroup/projects/magellan">Magellan</a>
					framework with auto generated features based on string
					similarity.
				</li>
				<li>a supervised experiment using the <a
						href="https://github.com/anhaidgroup/deepmatcher">deepmatcher</a>
					framework which offers multiple architectures for
					matching textual data.
				</li>
			</ol>
			<p>These experiments are performed for each of the four training sets to explore the learning curve for the different families of algorithms. </p>
				<span id="toc5.1"></span>
			<h3>5.1 Experimental Setup</h3>
			<p>The experiments use various combinations of the features title, description, brand and additionally
				specification table content. We applied the following preprocessing operations to the values of these
				attributes: We remove non-alphanumeric characters, stopwords (using <a
					href="https://www.nltk.org/">NLTK</a>),
				and
				lowercase all values.</p>
			<p> For the unsupervised TF/IDF and supervised word co-occurrence experiments, different combinations of
				features are concatenated
				and converted either into TF/IDF or binary word occurrence vectors. In case of the unsupervised experiment,
				the TF/IDF vectors for a pair are
				compared using cosine similarity with thresholds from 0 to 1 in steps of 0.01. The wordcount vectors for
				the first supervised experiment are
				combined into binary word co-occurrence vectors for each pair, whose elements serve as input features
				for the classifiers.
				For the Magellan experiment, we use the automatic feature generation functionality
				of the framework and use all of the created similarity scores as input for the classifiers. </p>

			<p>

			</p>
			<p>
				The deepmatcher experiments are conducted using pre-trained character-based <a
					href="https://fasttext.cc/docs/en/pretrained-vectors.html">fastText</a>
				embeddings (on English
				Wikipedia).
				The deepmatcher models themselves are trained for 15 epochs each using default parameters apart from
				batch size and pos-neg ratio. The pos-neg ratio
				is set to the closest integer value corresponding to the true ratio of positives and negatives in each
				of the training sets. The batch size is chosen as large as possible,
				so that the most complex model (hybrid) does not cause a VRAM memory error during training.
				<!--TODO: maybe add table with pos-negs and batch size-->
				Every model is trained three times and the resulting P, R and F1 values are averaged.
				Furthermore the deepmatcher implementation requires the training set to be split into training and
				validation
				set. This validation set is used to avoid overfitting to the training set by only selecting the
				resulting model
				of an epoch if it has a higher validation score
				than any model from a prior epoch. We randomly split (stratified by label) our training sets with a
				ratio of 4:1 for this purpose. As deepmatcher never sees this validation set during training we create
				parity with
				the other supervised algorithms by using the same form
				of holdout validation for them using the same validation sets. To make these experiments reproducible to
				the community,
				the validation pair ids are made available for <a href="#toc7">download</a>.

				All of the supervised experiments apart from deepmatcher use XGBoost and the <a
					href="https://scikit-learn.org/stable/">scikit-learn</a>
				library implementations of
				Logistic Regression, Naive Bayes, LinearSVC, Decision Tree and Random Forest.

				For all experiments using scikit-learn, we use Gridsearch or RandomizedSearch with holdout validation
				to optimize model
				parameters. </p>
				<span id="toc5.2"></span>
			<h3>5.2 Results</h3>
			<p>Table 3 shows the results of the experiments for the best performing model of each method for each of the
				four training set sizes. You can use the size selector at the top of the table to select a specific size.
				The experiments show that deepmatcher using an RNN reaches the highest F1 score 0.90 over all categories using the xlarge training set. 
				In this experiments deepmatcher outperforms the best traditional symbolic matching method (random forest using term co-occurrence as features) 
				by a margin of 16% in F1.
			</p>
			<div style="margin-top:2em;">
				<div style="float: left;margin-right: 2.5em">
					<div class="tab">
						<button class="tablinks" onclick="openExpResult(event, 'unsup')">small</button>
						<button class="tablinks" onclick="openExpResult(event, 'supwc')">medium</button>
						<button class="tablinks" onclick="openExpResult(event, 'supmg')">large</button>
						<button class="tablinks" onclick="openExpResult(event, 'supdm')" id="defaultOpen">xlarge</button>
					</div>
					<div id="unsup" class="tabcontent">
						<table class="smalltable">
							<caption style="margin-top: 1em">Table 3: Experimental results</caption>
							<tr>
								<td>Method</td>
								<td>Category</td>
								<td>Classifier</td>
								<td>Features</td>
								<td>P</td>
								<td>R</td>
								<td>F1</td>
							</tr>
							<tr>
								<td>TFIDF-cosine</td>
								<td>Computers</td>
								<td>TFIDF-cosine</td>
								<td>title+desc+brand</td>
								<td>42</td>
								<td>89</td>
								<td>57</td>
							</tr>
							<tr>
								<td></td>
								<td>Cameras</td>
								<td>TFIDF-cosine</td>
								<td>title+desc</td>
								<td>53</td>
								<td>80</td>
								<td>64</td>
							</tr>
							<tr>
								<td></td>
								<td>Watches</td>
								<td>TFIDF-cosine</td>
								<td>title</td>
								<td>51</td>
								<td>82</td>
								<td>63</td>
							</tr>
							<tr>
								<td></td>
								<td>Shoes</td>
								<td>TFIDF-cosine</td>
								<td>title</td>
								<td>45</td>
								<td>77</td>
								<td>57</td>
							</tr>
							<tr>
								<td></td>
								<td>All</td>
								<td>TFIDF-cosine</td>
								<td>title</td>
								<td>46</td>
								<td>74</td>
								<td>57</td>
							</tr>
							<tr>
								<td>magellan</td>
								<td>Computers</td>
								<td>RandomForest</td>
								<td>title+desc+brand+specTable</td>
								<td>50.47</td>
								<td>71.67</td>
								<td>59.23</td>
							</tr>
							<tr>
								<td></td>
								<td>Cameras</td>
								<td>LogisticRegression
								</td>
								<td>title+desc+brand+specTable
								</td>
								<td>42.01
								</td>
								<td>82.33</td>
								<td>55.63
								</td>
							</tr>
							<tr>
								<td></td>
								<td>Watches</td>
								<td>RandomForest</td>
								<td>title+desc+brand+specTable
								</td>
								<td>60.16
								</td>
								<td>76
								</td>
								<td>67.16
								</td>
							</tr>
							<tr>
								<td></td>
								<td>Shoes</td>
								<td>RandomForest</td>
								<td>title+desc+brand
								</td>
								<td>50.48
								</td>
								<td>87.67
								</td>
								<td>64.07
								</td>
							</tr>
							<tr>
								<td></td>
								<td>All</td>
								<td>RandomForest</td>
								<td>title+desc+brand
								</td>
								<td>47.73
								</td>
								<td>82.17
								</td>
								<td>60.38
								</td>
							</tr>
							<tr>
								<td>Co-Occ</td>
								<td>Computers</td>
								<td>LinearSVC
								</td>
								<td>title+desc+brand+specTable
								</td>
								<td>53.09
								</td>
								<td>71.67
								</td>
								<td>60.99
								</td>
							</tr>
							<tr>
								<td></td>
								<td>Cameras</td>
								<td>LogisticRegression
								</td>
								<td>title
								</td>
								<td>52.31
								</td>
								<td>75.33
								</td>
								<td>61.75
								</td>
							</tr>
							<tr>
								<td></td>
								<td>Watches</td>
								<td>LinearSVC
								</td>
								<td>title+desc+brand+specTable
								</td>
								<td>61.2
								</td>
								<td>64.67
								</td>
								<td>62.88
								</td>
							</tr>
							<tr>
								<td></td>
								<td>Shoes</td>
								<td>LinearSVC
								</td>
								<td>title
								</td>
								<td>63.32
								</td>
								<td>80
								</td>
								<td>70.69
								</td>
							</tr>
							<tr>
								<td></td>
								<td>All</td>
								<td>LinearSVC
								</td>
								<td>title
								</td>
								<td>54.6
								</td>
								<td>78.08
								</td>
								<td>64.27
								</td>
							</tr>
							<tr>
								<td>deepmatcher</td>
								<td>Computers</td>
								<td>RNN</td>
								<td>title
								</td>
								<td>67.36
								</td>
								<td>74.22
								</td>
								<td>70.55
								</td>
							</tr>
							<tr>
								<td></td>
								<td>Cameras</td>
								<td>RNN</td>
								<td>title
								</td>
								<td>70.42
								</td>
								<td>66.89
								</td>
								<td>68.59
								</td>
							</tr>
							<tr>
								<td></td>
								<td>Watches</td>
								<td>hybrid
								</td>
								<td>title</td>
								<td>54.78</td>
								<td>84</td>
								<td>66.32</td>
							</tr>
							<tr>
								<td></td>
								<td>Shoes</td>
								<td>hybrid
								</td>
								<td>title
								</td>
								<td>65.72
								</td>
								<td>84.55
								</td>
								<td>73.86
								</td>
							</tr>
							<tr>
								<td></td>
								<td>All</td>
								<td>hybrid
								</td>
								<td>title

								</td>
								<td>67.08

								</td>
								<td>88.61

								</td>
								<td>76.34

								</td>
							</tr>
						</table>
					</div>
					<div id="supwc" class="tabcontent">
						<table class="smalltable">
							<caption style="margin-top: 1em">Table 3: Experimental results</caption>
							<tr>
								<td>Method</td>
								<td>Category</td>
								<td>Classifier</td>
								<td>Features</td>
								<td>P</td>
								<td>R</td>
								<td>F1</td>
							</tr>
							<tr>
								<td>TFIDF-cosine</td>
								<td>Computers</td>
								<td>TFIDF-cosine</td>
								<td>title+desc+brand</td>
								<td>42</td>
								<td>89</td>
								<td>57</td>
							</tr>
							<tr>
								<td></td>
								<td>Cameras</td>
								<td>TFIDF-cosine</td>
								<td>title+desc</td>
								<td>53</td>
								<td>80</td>
								<td>64</td>
							</tr>
							<tr>
								<td></td>
								<td>Watches</td>
								<td>TFIDF-cosine</td>
								<td>title</td>
								<td>51</td>
								<td>82</td>
								<td>63</td>
							</tr>
							<tr>
								<td></td>
								<td>Shoes</td>
								<td>TFIDF-cosine</td>
								<td>title</td>
								<td>45</td>
								<td>77</td>
								<td>57</td>
							</tr>
							<tr>
								<td></td>
								<td>All</td>
								<td>TFIDF-cosine</td>
								<td>title</td>
								<td>46</td>
								<td>74</td>
								<td>57</td>
							</tr>
							<tr>
								<td>magellan</td>
								<td>Computers</td>
								<td>RandomForest</td>
								<td>title+desc+brand+specTable
								</td>
								<td>50.78
								</td>
								<td>87
								</td>
								<td>64.13
								</td>
							</tr>
							<tr>
								<td></td>
								<td>Cameras</td>
								<td>RandomForest

								</td>
								<td>title+desc+brand+specTable

								</td>
								<td>49.66

								</td>
								<td>74
								</td>
								<td>59.44

								</td>
							</tr>
							<tr>
								<td></td>
								<td>Watches</td>
								<td>XGBoost
								</td>
								<td>title+desc+brand+specTable

								</td>
								<td>68.98

								</td>
								<td>63

								</td>
								<td>65.85

								</td>
							</tr>
							<tr>
								<td></td>
								<td>Shoes</td>
								<td>RandomForest</td>
								<td>title+desc+brand

								</td>
								<td>50

								</td>
								<td>85

								</td>
								<td>62.96

								</td>
							</tr>
							<tr>
								<td></td>
								<td>All</td>
								<td>RandomForest</td>
								<td>title+desc+brand+specTable
								</td>
								<td>49.63
								</td>
								<td>78.25
								</td>
								<td>60.74
								</td>
							</tr>
							<tr>
								<td>Co-Occ</td>
								<td>Computers</td>
								<td>LinearSVC
								</td>
								<td>title+desc+brand+specTable
								</td>
								<td>68.33
								</td>
								<td>82
								</td>
								<td>74.55
								</td>
							</tr>
							<tr>
								<td></td>
								<td>Cameras</td>
								<td>LogisticRegression
								</td>
								<td>title+desc+brand
								</td>
								<td>68.91
								</td>
								<td>71.67
								</td>
								<td>70.26
								</td>
							</tr>
							<tr>
								<td></td>
								<td>Watches</td>
								<td>LogisticRegression
								</td>
								<td>title
								</td>
								<td>62.73
								</td>
								<td>78
								</td>
								<td>69.54
								</td>
							</tr>
							<tr>
								<td></td>
								<td>Shoes</td>
								<td>LogisticRegression
								</td>
								<td>title
								</td>
								<td>74.13
								</td>
								<td>85
								</td>
								<td>79.19
								</td>
							</tr>
							<tr>
								<td></td>
								<td>All</td>
								<td>LogisticRegression
								</td>
								<td>title
								</td>
								<td>74.93
								</td>
								<td>68
								</td>
								<td>71.3
								</td>
							</tr>
							<tr>
								<td>deepmatcher</td>
								<td>Computers</td>
								<td>RNN</td>
								<td>title
								</td>
								<td>71.78
								</td>
								<td>85.11
								</td>
								<td>77.82
								</td>
							</tr>
							<tr>
								<td></td>
								<td>Cameras</td>
								<td>RNN</td>
								<td>title
								</td>
								<td>74.26
								</td>
								<td>79.11
								</td>
								<td>76.53
								</td>
							</tr>
							<tr>
								<td></td>
								<td>Watches</td>
								<td>RNN</td>
								<td>title+description+brand
								</td>
								<td>76.04
								</td>
								<td>83
								</td>
								<td>79.31
								</td>
							</tr>
							<tr>
								<td></td>
								<td>Shoes</td>
								<td>RNN</td>
								<td>title
								</td>
								<td>74.36
								</td>
								<td>85.45
								</td>
								<td>79.48
								</td>
							</tr>
							<tr>
								<td></td>
								<td>All</td>
								<td>RNN</td>
								<td>title+description
								</td>
								<td>75.16
								</td>
								<td>85.47
								</td>
								<td>79.94
								</td>
							</tr>
						</table>
					</div>
					<div id="supmg" class="tabcontent">
						<table class="smalltable">
							<caption style="margin-top: 1em">Table 3: Experimental results</caption>
							<tr>
								<td>Method</td>
								<td>Category</td>
								<td>Classifier</td>
								<td>Features</td>
								<td>P</td>
								<td>R</td>
								<td>F1</td>
							</tr>
							<tr>
								<td>TFIDF-cosine</td>
								<td>Computers</td>
								<td>TFIDF-cosine</td>
								<td>title+desc+brand</td>
								<td>42</td>
								<td>89</td>
								<td>57</td>
							</tr>
							<tr>
								<td></td>
								<td>Cameras</td>
								<td>TFIDF-cosine</td>
								<td>title+desc</td>
								<td>53</td>
								<td>80</td>
								<td>64</td>
							</tr>
							<tr>
								<td></td>
								<td>Watches</td>
								<td>TFIDF-cosine</td>
								<td>title</td>
								<td>51</td>
								<td>82</td>
								<td>63</td>
							</tr>
							<tr>
								<td></td>
								<td>Shoes</td>
								<td>TFIDF-cosine</td>
								<td>title</td>
								<td>45</td>
								<td>77</td>
								<td>57</td>
							</tr>
							<tr>
								<td></td>
								<td>All</td>
								<td>TFIDF-cosine</td>
								<td>title</td>
								<td>46</td>
								<td>74</td>
								<td>57</td>
							</tr>
							<tr>
								<td>magellan</td>
								<td>Computers</td>
								<td>XGBoost
								</td>
								<td>title+desc+brand+specTable
								</td>
								<td>69.1
								</td>
								<td>69.33
								</td>
								<td>69.22
								</td>
							</tr>
							<tr>
								<td></td>
								<td>Cameras</td>
								<td>LogisticRegression
								</td>
								<td>title+desc+brand+specTable

								</td>
								<td>51.38

								</td>
								<td>74.33
								</td>
								<td>60.76

								</td>
							</tr>
							<tr>
								<td></td>
								<td>Watches</td>
								<td>RandomForest</td>
								<td>title+desc+brand+specTable

								</td>
								<td>59.17

								</td>
								<td>80.67

								</td>
								<td>68.27

								</td>
							</tr>
							<tr>
								<td></td>
								<td>Shoes</td>
								<td>RandomForest</td>
								<td>title+desc+brand+specTable

								</td>
								<td>52.15

								</td>
								<td>81

								</td>
								<td>63.45

								</td>
							</tr>
							<tr>
								<td></td>
								<td>All</td>
								<td>RandomForest</td>
								<td>title+desc+brand+specTable
								</td>
								<td>49.74
								</td>
								<td>80.25
								</td>
								<td>61.42
								</td>
							</tr>
							<tr>
								<td>Co-Occ</td>
								<td>Computers</td>
								<td>LinearSVC
								</td>
								<td>title+desc+brand+specTable
								</td>
								<td>83.8
								</td>
								<td>79.33
								</td>
								<td>81.51
								</td>
							</tr>
							<tr>
								<td></td>
								<td>Cameras</td>
								<td>LogisticRegression
								</td>
								<td>title
								</td>
								<td>88.76
								</td>
								<td>76.33
								</td>
								<td>82.08
								</td>
							</tr>
							<tr>
								<td></td>
								<td>Watches</td>
								<td>LogisticRegression

								</td>
								<td>title+desc+brand+specTable

								</td>
								<td>84.5

								</td>
								<td>72.67

								</td>
								<td>78.14

								</td>
							</tr>
							<tr>
								<td></td>
								<td>Shoes</td>
								<td>LinearSVC
								</td>
								<td>title+desc
								</td>
								<td>82.61
								</td>
								<td>63.33
								</td>
								<td>71.7
								</td>
							</tr>
							<tr>
								<td></td>
								<td>All</td>
								<td>LinearSVC
								</td>
								<td>title+desc+brand+specTable
								</td>
								<td>80.29
								</td>
								<td>69.92
								</td>
								<td>74.74
								</td>
							</tr>
							<tr>
								<td>deepmatcher</td>
								<td>Computers</td>
								<td>RNN</td>
								<td>title
								</td>
								<td>86.46
								</td>
								<td>92.89
								</td>
								<td>89.55
								</td>
							</tr>
							<tr>
								<td></td>
								<td>Cameras</td>
								<td>hybrid
								</td>
								<td>title
								</td>
								<td>88.19
								</td>
								<td>86.22
								</td>
								<td>87.19
								</td>
							</tr>
							<tr>
								<td></td>
								<td>Watches</td>
								<td>RNN</td>
								<td>title
								</td>
								<td>90.17
								</td>
								<td>92.44
								</td>
								<td>91.28
								</td>
							</tr>
							<tr>
								<td></td>
								<td>Shoes</td>
								<td>RNN</td>
								<td>title
								</td>
								<td>88.36
								</td>
								<td>92.56
								</td>
								<td>90.39
								</td>
							</tr>
							<tr>
								<td></td>
								<td>All</td>
								<td>RNN</td>
								<td>title
								</td>
								<td>87.81
								</td>
								<td>90.72
								</td>
								<td>89.24
								</td>
							</tr>
						</table>
					</div>
					<div id="supdm" class="tabcontent">
						<table class="smalltable">
							<caption style="margin-top: 1em">Table 3: Experimental results</caption>
							<tr>
								<td>Method</td>
								<td>Category</td>
								<td>Classifier</td>
								<td>Features</td>
								<td>P</td>
								<td>R</td>
								<td>F1</td>
							</tr>
							<tr>
									<td>TFIDF-cosine</td>
									<td>Computers</td>
									<td>TFIDF-cosine</td>
									<td>title+desc+brand</td>
									<td>42</td>
									<td>89</td>
									<td>57</td>
								</tr>
								<tr>
									<td></td>
									<td>Cameras</td>
									<td>TFIDF-cosine</td>
									<td>title+desc</td>
									<td>53</td>
									<td>80</td>
									<td>64</td>
								</tr>
								<tr>
									<td></td>
									<td>Watches</td>
									<td>TFIDF-cosine</td>
									<td>title</td>
									<td>51</td>
									<td>82</td>
									<td>63</td>
								</tr>
								<tr>
									<td></td>
									<td>Shoes</td>
									<td>TFIDF-cosine</td>
									<td>title</td>
									<td>45</td>
									<td>77</td>
									<td>57</td>
								</tr>
								<tr>
									<td></td>
									<td>All</td>
									<td>TFIDF-cosine</td>
									<td>title</td>
									<td>46</td>
									<td>74</td>
									<td>57</td>
								</tr>
							<tr>
								<td>magellan</td>
								<td>Computers</td>
								<td>XGBoost
								</td>
								<td>title+desc+brand+specTable
								</td>
								<td>72.32
								</td>
								<td>65.33
								</td>
								<td>68.65
								</td>
							</tr>
							<tr>
								<td></td>
								<td>Cameras</td>
								<td>XGBoost

								</td>
								<td>title+desc+brand+specTable

								</td>
								<td>73.87

								</td>
								<td>54.67
								</td>
								<td>62.84

								</td>
							</tr>
							<tr>
								<td></td>
								<td>Watches</td>
								<td>XGBoost
								</td>
								<td>title+desc+brand+specTable

								</td>
								<td>74.15

								</td>
								<td>50.67

								</td>
								<td>60.20

								</td>
							</tr>
							<tr>
								<td></td>
								<td>Shoes</td>
								<td>RandomForest</td>
								<td>title+desc+brand+specTable

								</td>
								<td>51.33

								</td>
								<td>83.67

								</td>
								<td>63.62

								</td>
							</tr>
							<tr>
								<td></td>
								<td>All</td>
								<td>RandomForest</td>
								<td>title+desc+brand+specTable
								</td>
								<td>48.68
								</td>
								<td>78.42
								</td>
								<td>60.07
								</td>
							</tr>
							<tr>
								<td>Co-Occ</td>
								<td>Computers</td>
								<td>LinearSVC
								</td>
								<td>title+desc+brand+specTable
								</td>
								<td>86.74
								</td>
								<td>80.67
								</td>
								<td>83.59
								</td>
							</tr>
							<tr>
								<td></td>
								<td>Cameras</td>
								<td>LinearSVC
								</td>
								<td>title+desc+brand+specTable
								</td>
								<td>81.51
								</td>
								<td>64.67
								</td>
								<td>72.12
								</td>
							</tr>
							<tr>
								<td></td>
								<td>Watches</td>
								<td>LinearSVC
								</td>
								<td>title+desc+brand+specTable
								</td>
								<td>88.14
								</td>
								<td>69.33
								</td>
								<td>77.61
								</td>
							</tr>
							<tr>
								<td></td>
								<td>Shoes</td>
								<td>LogisticRegression
								</td>
								<td>title
								</td>
								<td>86.14
								</td>
								<td>58.00
								</td>
								<td>69.32
								</td>
							</tr>
							<tr>
								<td></td>
								<td>All</td>
								<td>LogisticRegression</td>
								<td>title+desc+brand+specTable
								</td>
								<td>85.97
								</td>
								<td>66.92
								</td>
								<td>75.26
								</td>
							</tr>
							<tr>
								<td>deepmatcher</td>
								<td>Computers</td>
								<td>RNN</td>
								<td>title+desc+brand
								</td>
								<td>89.75
								</td>
								<td>91.89
								</td>
								<td>90.80
								</td>
							</tr>
							<tr>
								<td></td>
								<td>Cameras</td>
								<td>RNN</td>
								<td>title+description+brand+specTable
								</td>
								<td>89.22
								</td>
								<td>89.22
								</td>
								<td>89.21
								</td>
							</tr>
							<tr>
								<td></td>
								<td>Watches</td>
								<td>RNN</td>
								<td>title+description+brand+specTable
								</td>
								<td>92.73
								</td>
								<td>94.22
								</td>
								<td>93.45
								</td>
							</tr>
							<tr>
								<td></td>
								<td>Shoes</td>
								<td>RNN</td>
								<td>title
								</td>
								<td>93.16
								</td>
								<td>92.11
								</td>
								<td>92.61
								</td>
							</tr>
							<tr>
								<td></td>
								<td>All</td>
								<td>RNN</td>
								<td>title+description
								</td>
								<td>92.04
								</td>
								<td>88.36
								</td>
								<td>90.16
								</td>
							</tr>
						</table>
					</div>

					<p> Figure 7 shows the learning
						curves for the supervised algorithms for the Computers and combined sets (All).
						Figure 8 shows the learning curves for each of the four deepmatcher models. Overall the deepmatcher approach works best for all training set sizes when compared to
						the traditional methods. Among the deepmatcher models themselves, the RNN consistently achieves the highest F1 on the gold standard, followed by the hybrid, attention and SIF models.

					<figure style='float:left;margin-top:2em'>
							<figcaption>
									<strong>Figure 7: Learning curves of the supervised methods with increasing training set
										size</strong></figcaption>
						<img width='20%' src="images/all_baseline_comparison.png">
						<img width='20%' src="images/computers_baseline_comparison.png">
						
					</figure>
					<figure>
							<figcaption>
									<strong>Figure 8: Learning curves of the four deepmatcher models with increasing training set
										size</strong></figcaption>
							</figure>
							<img width='20%' style='margin-left:1.5em' src="images/all_dm_comparison.png">
							<img width='20%' src="images/computers_dm_comparison.png">
				</div>


			</div>
<h2></h2>
			<span id="toc6"></span>
			<h2>6 Download</h2>
			
			<p>
				We offer the WDC Product corpus for Large-scale Product Matching as well as its English subset for
				public download in JSON format. The JSON file contains the fields described in section 2.2 for each offer.

				

			</p>
			<p>
				The Gold Standard and Training Subset JSON files contain product offer pairs where each attribute exists
				twice, once with the suffix _left
				for the left offer of a pair and once with the suffix _right for the right offer. Additionally there is
				the attribute pair_id which uniquely
				identifies each pair by concatenating their individual ids in the form id_left + '#' + id_right.
				Finally the binary attribute label signifies if two product offers refer to the same product or not.
				We offer all files both non-normalized and normalized. The non-normalized files contain all raw textual properties while for the normalized files all values are lowercased 
				and all non alphanumeric characters have been removed.
			</p>

			All JSON files can easily be imported into a pandas dataframe using the following function call (big corpus
			files need a considerable amount of RAM memory):<br><br>
			<code>import pandas as pd<br>
						df = pd.read_json('dataset.json.gz', compression='gzip', lines=True)
				</code>
				<p>
				Additionally we offer a csv file containing a mapping from the unique ids of each offer to the URL where this offer originated from. This allows for further scraping of information to enrich the dataset if desired.
			</p>
				<p>
				If you want to map offers from version 2 of the corpus back to version 1, we offer a tsv file which allows you to do this.
				Each offer in v1 is uniquely identified by the concatenation of nodeID and url with one whitespace in between (nodeID + ' ' + url).
			</p>
			<p>
				<p>
					Code to reproduce the baseline experiments can be found <a href="https://github.com/Weyoun2211/wdc-lspc-v2">here</a>. The self-trained fastText model is available <a href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/fastText/self-trained.bin">here</a>.
				</p>
				<p>
					<b>Update:</b> Results on the recently added SWC Test set can be found in the summary paper of the challenge as well as in the system submission papers found in the corresponding <a href="http://ceur-ws.org/Vol-2720/">CEUR Workshop proceedings</a>.
				</p>
				<table>
					<tbody>
						<tr>
							<td><b>File</b></td>
							<td><b>Non-normalized Sample</b></td>
							<td><b>Size</b></td>
							<td><b>Non-normalized Download</b></td>
							<td><b>Normalized Sample</b></td>
							<td><b>Size</b></td>
							<td><b>Normalized Download</b></td>
							
						</tr>



						<tr>
							<td>Product Data Corpus (Full)</td>
							<td><a
									href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2_nonnorm/samples/offers_corpus_all_v2_sample_non_norm.json">sample_offers</a>
								</td>
							<td>6.5GB</td>
							<td><a
									href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2_nonnorm/offers_corpus_all_v2_non_norm.json.gz">offers_corpus_all_v2_non_norm.json.gz
							</td>
							<td><a
									href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/samples/offers_corpus_all_v2_sample.json">sample_offers</a>
								</td>
							<td>4.5GB</td>
							<td><a
									href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/offers_corpus_all_v2.json.gz">offers_corpus_all_v2.json.gz
							</td>
							
						</tr>
						<tr>
							<td>Product Data Corpus (English)</td>

							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2_nonnorm/samples/offers_corpus_english_v2_sample_non_norm.json">sample_offers_english</a>							</td>
							<td>3.7GB</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2_nonnorm/offers_corpus_english_v2_non_norm.json.gz">offers_corpus_english_v2_non_norm.json.gz
							</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/samples/offers_corpus_english_v2_sample.json">sample_offers_english</a>							</td>
							<td>2.7GB</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/offers_corpus_english_v2.json.gz">offers_corpus_english_v2.json.gz
							</td>
							
						</tr>
						
						<tr>
							<td>Training Sets Computers</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2_nonnorm/samples/computers_train_xlarge_sample.json">computers_train_sample</a>							</td>
							<td>54.5MB</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2_nonnorm/trainsets/computers_train.zip">computers_train.zip
							</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/samples/computers_train_xlarge_sample.json">computers_train_sample</a>							</td>
							<td>16.3MB</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/trainsets/computers_train.zip">computers_train.zip
							</td>
						</tr>
						<tr>
							<td>Training Sets Cameras</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2_nonnorm/samples/cameras_train_xlarge_sample.json">cameras_train_sample</a>							</td>
							<td>45.2MB</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2_nonnorm/trainsets/cameras_train.zip">cameras_train.zip
							</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/samples/cameras_train_xlarge_sample.json">cameras_train_sample</a>							</td>
							<td>15.4MB</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/trainsets/cameras_train.zip">cameras_train.zip
							</td>
						</tr>
						
						<tr>
							<td>Training Sets Watches</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2_nonnorm/samples/watches_train_xlarge_sample.json">watches_train_sample</a>							</td>
							<td>48.2MB</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2_nonnorm/trainsets/watches_train.zip">watches_train.zip
							</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/samples/watches_train_xlarge_sample.json">watches_train_sample</a>							</td>
							<td>13.9MB</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/trainsets/watches_train.zip">watches_train.zip
							</td>
						</tr>
						<tr>
							<td>Training Sets Shoes</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2_nonnorm/samples/shoes_train_xlarge_sample.json">shoes_train_sample</a>							</td>
							<td>36 MB</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2_nonnorm/trainsets/shoes_train.zip">shoes_train.zip
							</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/samples/shoes_train_xlarge_sample.json">shoes_train_sample</a>							</td>
							<td>11.9MB</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/trainsets/shoes_train.zip">shoes_train.zip
							</td>
						</tr>
						<tr>
							<td>Training Sets All</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2_nonnorm/samples/all_train_xlarge_sample.json">all_train_sample</a>							</td>
							<td>213.3 MB</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2_nonnorm/trainsets/all_train.zip">all_train.zip
							</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/samples/all_train_xlarge_sample.json">all_train_sample</a>							</td>
							<td>57.6MB</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/trainsets/all_train.zip">all_train.zip
							</td>
						</tr>
						<tr>
							<td>Validation Sets Computers</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/samples/computers_valid_xlarge_sample.txt">computers_valid_sample</a>							</td>
							<td>153.8KB</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/validsets/computers_valid.zip">computers_valid.zip
							</td>
						</tr>
						<tr>
							<td>Validation Sets Cameras</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/samples/cameras_valid_xlarge_sample.txt">cameras_valid_sample</a>							</td>
							<td>92KB</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/validsets/cameras_valid.zip">cameras_valid.zip
							</td>
						</tr>
						<tr>
							<td>Validation Sets Watches</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/samples/watches_valid_xlarge_sample.txt">watches_valid_sample</a>							</td>
							<td>129.7KB</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/validsets/watches_valid.zip">watches_valid.zip
							</td>
						</tr>
						<tr>
							<td>Validation Sets Shoes</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/samples/shoes_valid_xlarge_sample.txt">shoes_valid_sample</a>							</td>
							<td>92.7KB</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/validsets/shoes_valid.zip">shoes_valid.zip
							</td>
						</tr>
						<tr>
							<td>Validation Sets All</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/samples/all_valid_xlarge_sample.txt">all_valid_sample</a>							</td>
							<td>541.4KB</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/validsets/all_valid.zip">all_valid.zip
							</td>
						</tr>
						<tr>
							<td>Gold Standard Computers</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2_nonnorm/samples/computers_gs_sample.json">computers_gs_sample</a></td>

							<td>528KB</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2_nonnorm/goldstandards/computers_gs.json.gz">computers_gs.json.gz
							</td>
							
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/samples/computers_gs_sample.json">computers_gs_sample</a></td>

							<td>294.5KB</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/goldstandards/computers_gs.json.gz">computers_gs.json.gz
							</td>

						</tr>
						
						<tr>
							<td>Gold Standard Cameras</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2_nonnorm/samples/cameras_gs_sample.json">cameras_gs_sample</a></td>
							<td>705KB</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2_nonnorm/goldstandards/cameras_gs.json.gz">cameras_gs.json.gz
							</td>
							
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/samples/cameras_gs_sample.json">cameras_gs_sample</a></td>
							<td>369.3KB</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/goldstandards/cameras_gs.json.gz">cameras_gs.json.gz
							</td>

						</tr>
						<tr>
							<td>Gold Standard Watches</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2_nonnorm/samples/watches_gs_sample.json">watches_gs_sample</a></td>
							<td>551KB</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2_nonnorm/goldstandards/watches_gs.json.gz">watches_gs.json.gz
							</td>
							
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/samples/watches_gs_sample.json">watches_gs_sample</a></td>
							<td>311KB</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/goldstandards/watches_gs.json.gz">watches_gs.json.gz
							</td>

						</tr>
						<tr>
							<td>Gold Standard Shoes</td>
							
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2_nonnorm/samples/shoes_gs_sample.json">shoes_gs_sample</a></td>
							<td>490KB</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2_nonnorm/goldstandards/shoes_gs.json.gz">shoes_gs.json.gz
							</td>

							
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/samples/shoes_gs_sample.json">shoes_gs_sample</a></td>
							<td>274.3KB</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/goldstandards/shoes_gs.json.gz">shoes_gs.json.gz
							</td>

						</tr>
						<tr>
							<td>Gold Standard All</td>
							
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2_nonnorm/samples/all_gs_sample.json">all_gs_sample</a></td>
							<td>2.6MB</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2_nonnorm/goldstandards/all_gs.json.gz">all_gs.json.gz
							</td>
							
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/samples/all_gs_sample.json">all_gs_sample</a></td>
							<td>1.2MB</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/goldstandards/all_gs.json.gz">all_gs.json.gz
							</td>

						</tr>
						<tr>
							<td>SWC Test set (Computers)</td>
							<td>
							<td></td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/swc/task1_testset_1500_with_labels.json.gz">task1_testset_1500_with_labels.json.gz
							</td>
							
							<td></td>

							<td></td>
							<td>
							</td>

						</tr>
						<tr>
							<td>id-url-mapping</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/samples/id_url_mapping_sample.txt">id_url_mapping_sample</a></td>
							<td>1GB</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/id_url_mapping.csv.gz">id_url_mapping.csv.gz
							</td>

						</tr>
						<tr>
							<td>HTML corpus
							</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/samples/sample_html.json">sample_html</a></td>
							<td>484.GB</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaledatacorpusHTML/html_pages.zip">html_pages.zip
							</td>

						</tr>
						<tr>
							<td>v1 to v2 id mapping
							</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/v1_v2_mapping_sample.txt">v1_v2_mapping_sample</a></td>
							<td>1.5GB</td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/v1_v2_mapping.tsv.gz">v1_v2_mapping.tsv.gz
							</td>

						</tr>
						<tr>
							<td>Computers pre-training set
							</td>
							<td></td>
							<td></td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/pretrain/pre-training_computers_only_new_15.json.gz">pre-training_computers.json.gz
							</td>

						</tr>
						<tr>
							<td>4cat pre-training set
							</td>
							<td></td>
							<td></td>
							<td><a
								href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/pretrain/pre-training_4cat_new_5.json.gz">pre-training_4cat.json.gz
							</td>

						</tr>



					</tbody>
				</table>
				<span id="toc7"></span>
				<h2>7 Feedback</h2>
				<p>Please send questions and feedback to the <a
						href="http://groups.google.com/group/web-data-commons">Web Data
						Commons Google Group</a>.<br /><br />
					More information about Web Data Commons is found <a href="../../index.html">here</a>.</p>

				<span id="toc8"></span>
				<h2>8 References</h2>
				<ol>
					<li>Zhang, Z., Bizer, C., Peeters, R., and Primpeli, A., <a
						href="http://ceur-ws.org/Vol-2720/paper1.pdf"
						target="_blank">MWPD2020: Semantic Web challenge on Mining the Web of HTML-embedded product data</a>. in CEUR Workshop Proceedings, 2020, vol. 2720, pp. 2–18.</li>
					<li>Peeters, R., Primpeli, A., Wichtlhuber, B., and Bizer, C., 2020. <a
						href="http://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/v2/papers/WIMS2020_Peeters.pdf"
						target="_blank">Using schema.org Annotations for Training and Maintaining Product Matchers</a>. In The 10th International Conference on Web Intelligence, 
						Mining and Semantics (WIMS 2020)</li>
					<li><a id="PrPeBi2019"></a>Primpeli, A., Peeters, R., & Bizer, C.:
						<a href="https://dl.acm.org/citation.cfm?id=3316609">The WDC training dataset and gold standard
							for large-scale product matching</a>.
						In: Companion Proceedings of the 2019 World Wide Web Conference. pp. 381-386 ACM (2019).</li>
					<li>Mudgal, S. et al.: <a href="http://pages.cs.wisc.edu/~anhai/papers1/deepmatcher-sigmod18.pdf"
							target="_blank">Deep
							Learning for Entity Matching: A Design Space Exploration</a>. In: Proceedings of the 2018
						International
						Conference on Management of Data. pp. 19–34 ACM (2018).</li>
					<li>Ebraheem, M., Thirumuruganathan, S., Joty, S., Ouzzani, M., Tang, N.: <a
							href="http://www.vldb.org/pvldb/vol11/p1454-ebraheem.pdf" target="_blank">Distributed
							representations of tuples for entity resolution</a>. Proceedings of the VLDB
						Endowment. 11, 11, 1454-1467 (2018).</li>
					<li>Shah, K., Kopru, S., Ruvini, J.D.: <a href="http://aclweb.org/anthology/N18-3002"
							target="_blank">Neural
							Network based Extreme Classifcation and Similarity Models for Product Matching</a>. In:
						Proceedings of the 2018
						Conference of the North American Chapter of the Association for Computational Linguistics: Human
						Language
						Technologies,
						Volume 3. pp. 815 (2018).</li>
					<li>Luciano Barbosa: <a href="https://www.emeraldinsight.com/doi/full/10.1108/IJWIS-07-2018-0059"
							target="_blank">Learning
							representations of Web entities for entity resolution</a>. International Journal of Web
						Information Systems,
						https://doi.org/10.1108/IJWIS-07-2018-0059 (2018)</li>
					<li>Cheng Fu, Xianpei Han, et al.: <a
							href="https://www.ijcai.org/proceedings/2019/0689.pdf">End-to-end multi-perspective matching
							for entity resolution</a>. In Proceedings of the 28th International Joint Conference on
						Artificial Intelligence (IJCAI'19), 4961-4967 (2019).</li>
					<li>Qiu, D. et al.: <a href="http://www.vldb.org/pvldb/vol8/p2194-qiu.pdf" target="_blank">Dexter:
							large-scale
							discovery and extraction of product specifications on the web</a>. Proceedings of the VLDB
						Endowment. 8, 13,
						2194–2205 (2015).</li>
					<li>Köpcke, H. et al.: <a href="http://www.vldb.org/pvldb/vldb2010/papers/E04.pdf"
							target="_blank">Evaluation of
							entity resolution approaches on real-world match problems</a>. Proceedings of the VLDB
						Endowment. 3, 1–2,
						484–493 (2010).</li>
					<li>Petrovski, P., Bizer, C.: <a
							href="http://webdatacommons.org/productcorpus/paper/attribute_value_pair_extraction_from_specification.pdf"
							target="_blank">Extracting attribute-value pairs from product specifications on the web</a>.
						In: Proceedings of
						the International Conference on Web Intelligence. pp. 558–565 ACM (2017).</li>
					<li>Petrovski, P., Bryl, V., Bizer, C.: <a
							href="http://wwwconference.org/proceedings/www2014/companion/p1299.pdf"
							target="_blank">Integrating product data from websites offering microdata markup</a>. In:
						Proceedings of the
						23rd International Conference on World Wide Web - WWW 14 Companion. pp. 1299-1304 (2014).</li>
					
				</ol>
				<script type="text/javascript">
					$('#toc').toc({
						'selectors': 'h2', //elements to use as headings
						'container': '#toccontent', //element to find all selectors in
						'smoothScrolling': true, //enable or disable smooth scrolling on click
						'prefix': 'toc', //prefix for anchor tags and class names
						'highlightOnScroll': true, //add class to heading that is currently in focus
						'highlightOffset': 100, //offset to trigger the next headline
						'anchorName': function (i, heading, prefix) { //custom function for anchor name
							return prefix + i;
						}
					});
					$('[id*="link_"]').each(function () {
						var element = $(this);
						element.click(function (e) {
							e.preventDefault();
							var id = element.attr("id").split("_")[1];
							element.parent().removeClass("show").addClass("no-show");
							$('#charts_' + id).removeClass("no-show").addClass("show");
						});
					});
					$('[id*="colapse_"]').each(function () {
						var element = $(this);
						element.click(function (e) {
							e.preventDefault();
							var id = element.attr("id").split("_")[1];
							element.parent().removeClass("show").addClass("no-show");
							$('#intro_' + id).removeClass("no-show").addClass("show");
						});
					});
					document.getElementById("defaultOpen").click();
				</script>
</body>

</html>